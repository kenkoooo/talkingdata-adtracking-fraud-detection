{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version has improvements based on new feature engg techniques observed from different kernels. Below are few of them:\n",
    "- https://www.kaggle.com/graf10a/lightgbm-lb-0-9675\n",
    "- https://www.kaggle.com/rteja1113/lightgbm-with-count-features?scriptVersionId=2815638\n",
    "- https://www.kaggle.com/nuhsikander/lgbm-new-features-corrected?scriptVersionId=2852561\n",
    "- https://www.kaggle.com/aloisiodn/lgbm-starter-early-stopping-0-9539 (Original script)\n",
    "---\n",
    "**ここからコピー・改変**  \n",
    "https://www.kaggle.com/pranav84/lightgbm-fixing-unbalanced-data-lb-0-9680/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import psycopg2\n",
    "import lightgbm as lgb\n",
    "import json\n",
    "import time\n",
    "import gc\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../data/'\n",
    "dtypes = {\n",
    "    'id'                : 'uint32',\n",
    "    'click_id'          : 'float32',\n",
    "    'ip'                : 'uint32',\n",
    "    'app'               : 'uint16',\n",
    "    'device'            : 'uint16',\n",
    "    'os'                : 'uint16',\n",
    "    'channel'           : 'uint16',\n",
    "    'is_attributed'     : 'uint8',\n",
    "    'is_test'           : 'uint8',\n",
    "    'uq_user'           : 'uint32',\n",
    "    'app_pre'           : 'float16',\n",
    "    'app_post'          : 'float16',\n",
    "    'same_app_pre'      : 'float16',\n",
    "    'same_app_post'     : 'float16',\n",
    "    'chan_pre'          : 'float16',\n",
    "    'chan_post'         : 'float16',\n",
    "    'same_ch_pre'       : 'float16',\n",
    "    'same_ch_post'      : 'float16',\n",
    "    'interval_pre'      : 'float16',\n",
    "    'interval_post'     : 'float16',\n",
    "    'click_hour'        : 'uint8',\n",
    "    'cnt_day'           : 'uint32',\n",
    "    'cnt_1hour'         : 'uint16',\n",
    "    'cnt_1min'          : 'uint16'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_modelfit_nocv(params,\n",
    "                      dtrain,\n",
    "                      dvalid,\n",
    "                      predictors,\n",
    "                      target='target',\n",
    "                      objective='binary',\n",
    "                      metrics='auc',\n",
    "                      feval=None,\n",
    "                      early_stopping_rounds=20,\n",
    "                      num_boost_round=3000,\n",
    "                      verbose_eval=10,\n",
    "                      categorical_features=None):\n",
    "    lgb_params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': objective,\n",
    "        'metric':metrics,\n",
    "        'learning_rate': 0.01,\n",
    "        #'is_unbalance': 'true',  #because training data is unbalance (replaced with scale_pos_weight)\n",
    "        'num_leaves': 31,  # we should let it be smaller than 2^(max_depth)\n",
    "        'max_depth': -1,  # -1 means no limit\n",
    "        'min_child_samples': 20,  # Minimum number of data need in a child(min_data_in_leaf)\n",
    "        'max_bin': 255,  # Number of bucketed bin for feature values\n",
    "        'subsample': 0.6,  # Subsample ratio of the training instance.\n",
    "        'subsample_freq': 0,  # frequence of subsample, <=0 means no enable\n",
    "        'colsample_bytree': 0.3,  # Subsample ratio of columns when constructing each tree.\n",
    "        'min_child_weight': 5,  # Minimum sum of instance weight(hessian) needed in a child(leaf)\n",
    "        'subsample_for_bin': 200000,  # Number of samples for constructing bin\n",
    "        'min_split_gain': 0,  # lambda_l1, lambda_l2 and min_gain_to_split to regularization\n",
    "        'reg_alpha': 0,  # L1 regularization term on weights\n",
    "        'reg_lambda': 0,  # L2 regularization term on weights\n",
    "        'nthread': 4,\n",
    "        'verbose': 0,\n",
    "        'metric':metrics\n",
    "    }\n",
    "\n",
    "    lgb_params.update(params)\n",
    "\n",
    "    print(\"preparing validation datasets\")\n",
    "\n",
    "    xgtrain = lgb.Dataset(dtrain[predictors].values, label=dtrain[target].values,\n",
    "                          feature_name=predictors,\n",
    "                          categorical_feature=categorical_features\n",
    "                          )\n",
    "    xgvalid = lgb.Dataset(dvalid[predictors].values, label=dvalid[target].values,\n",
    "                          feature_name=predictors,\n",
    "                          categorical_feature=categorical_features\n",
    "                          )\n",
    "\n",
    "    evals_results = {}\n",
    "\n",
    "    bst1 = lgb.train(lgb_params, \n",
    "                     xgtrain, \n",
    "                     valid_sets=[xgtrain, xgvalid], \n",
    "                     valid_names=['train','valid'], \n",
    "                     evals_result=evals_results, \n",
    "                     num_boost_round=num_boost_round,\n",
    "                     early_stopping_rounds=early_stopping_rounds,\n",
    "                     verbose_eval=10, \n",
    "                     feval=feval)\n",
    "\n",
    "    n_estimators = bst1.best_iteration\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"n_estimators : \", n_estimators)\n",
    "    print(metrics+\":\", evals_results['valid'][metrics][n_estimators-1])\n",
    "\n",
    "    return bst1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000000, 25)\n",
      "CPU times: user 1min 33s, sys: 9.06 s, total: 1min 42s\n",
      "Wall time: 1min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path = '../../data/'\n",
    "train = pd.read_csv(path + 'train_mod' + '.csv', dtype=dtypes, nrows=50000000)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id  click_id  ip  app  device  os  channel  is_attributed  is_test  \\\n",
      "0  144482172       NaN   1    2       1   2      477              0        0   \n",
      "1  146120513       NaN   1    2       1   2      477              0        0   \n",
      "2  146134295       NaN   1    2       1   2      477              0        0   \n",
      "3  147103437       NaN   1    2       1   2      477              0        0   \n",
      "4  160258098       NaN   1    2       1   2      477              0        0   \n",
      "\n",
      "         click_time_ch   uq_user  app_pre  app_post  same_app_pre  \\\n",
      "0  2017-11-09 01:47:39  10020001      NaN       2.0           NaN   \n",
      "1  2017-11-09 04:08:39  10020001      2.0       2.0           1.0   \n",
      "2  2017-11-09 04:10:32  10020001      2.0       2.0           1.0   \n",
      "3  2017-11-09 06:03:35  10020001      2.0       2.0           1.0   \n",
      "4  2017-11-09 11:01:59  10020001      2.0      14.0           1.0   \n",
      "\n",
      "   same_app_post  chan_pre  chan_post  same_ch_pre  same_ch_post  \\\n",
      "0            1.0       NaN      477.0          NaN           1.0   \n",
      "1            1.0     477.0      477.0          1.0           1.0   \n",
      "2            1.0     477.0      477.0          1.0           1.0   \n",
      "3            1.0     477.0      477.0          1.0           1.0   \n",
      "4            0.0     477.0      449.0          1.0           0.0   \n",
      "\n",
      "   interval_pre  interval_post  click_hour  cnt_day  cnt_1hour  cnt_1min  \n",
      "0           NaN         8464.0           1        9          1         1  \n",
      "1        8464.0          113.0           4        9          2         1  \n",
      "2         113.0         6784.0           4        9          2         1  \n",
      "3        6784.0        17904.0           6        9          1         1  \n",
      "4       17904.0        41536.0          11        9          1         1  \n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    1.0\n",
       "Name: same_ch_pre, dtype: float16"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['same_ch_pre'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(train['interval_pre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                uint32\n",
       "click_id         float32\n",
       "ip                uint32\n",
       "app               uint16\n",
       "device            uint16\n",
       "os                uint16\n",
       "channel           uint16\n",
       "is_attributed      uint8\n",
       "is_test            uint8\n",
       "click_time_ch     object\n",
       "uq_user           uint32\n",
       "app_pre          float16\n",
       "app_post         float16\n",
       "same_app_pre     float16\n",
       "same_app_post    float16\n",
       "chan_pre         float16\n",
       "chan_post        float16\n",
       "same_ch_pre      float16\n",
       "same_ch_post     float16\n",
       "interval_pre     float16\n",
       "interval_post    float16\n",
       "click_hour         uint8\n",
       "cnt_day           uint32\n",
       "cnt_1hour         uint16\n",
       "cnt_1min          uint16\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32965171, 25) (17034829, 25)\n"
     ]
    }
   ],
   "source": [
    "# test_df = merge[merge.is_test == 1]\n",
    "# train_df = merge[(merge.is_test == 0) & (merge.click_date != '2017-11-09 00:00:00')]\n",
    "# val_df = merge[(merge.is_test == 0) & (merge.click_date == '2017-11-09 00:00:00')]\n",
    "\n",
    "train_df = train[train.click_time_ch < '2017-11-09 00:00:00']\n",
    "val_df = train[train.click_time_ch >= '2017-11-09 00:00:00']\n",
    "\n",
    "print(train_df.shape, val_df.shape)\n",
    "# del train\n",
    "# print(test_df.shape, train_df.shape, val_df.shape)\n",
    "# del merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'is_attributed'\n",
    "predictors = ['device', 'os', 'interval_pre', 'interval_post', \n",
    "              'app','app_pre', 'app_post', 'same_app_pre', 'same_app_post',\n",
    "              'channel','chan_pre', 'chan_post', 'same_ch_pre', 'same_ch_post',\n",
    "              'click_hour', 'cnt_1min']\n",
    "categorical = ['device', 'os',\n",
    "               'app','app_pre', 'app_post', 'same_app_pre', 'same_app_post',\n",
    "               'channel', 'chan_pre', 'chan_post', 'same_ch_pre', 'same_ch_post']\n",
    "# sub = pd.DataFrame()\n",
    "# sub['click_id'] = test_df['click_id'].astype('int')\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "preparing validation datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:681: UserWarning: categorical_feature in param dict is overrided.\n",
      "  warnings.warn('categorical_feature in param dict is overrided.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds.\n",
      "[10]\ttrain's auc: 0.940873\tvalid's auc: 0.923781\n",
      "[20]\ttrain's auc: 0.945573\tvalid's auc: 0.927928\n",
      "[30]\ttrain's auc: 0.950844\tvalid's auc: 0.934518\n",
      "[40]\ttrain's auc: 0.955751\tvalid's auc: 0.93994\n",
      "[50]\ttrain's auc: 0.957885\tvalid's auc: 0.941743\n",
      "[60]\ttrain's auc: 0.959324\tvalid's auc: 0.943011\n",
      "[70]\ttrain's auc: 0.960404\tvalid's auc: 0.94354\n",
      "[80]\ttrain's auc: 0.961176\tvalid's auc: 0.944131\n",
      "[90]\ttrain's auc: 0.961932\tvalid's auc: 0.944537\n",
      "[100]\ttrain's auc: 0.9626\tvalid's auc: 0.944984\n",
      "[110]\ttrain's auc: 0.963185\tvalid's auc: 0.945341\n",
      "[120]\ttrain's auc: 0.963823\tvalid's auc: 0.945625\n",
      "[130]\ttrain's auc: 0.964265\tvalid's auc: 0.945671\n",
      "[140]\ttrain's auc: 0.964783\tvalid's auc: 0.945871\n"
     ]
    }
   ],
   "source": [
    "print(\"Training...\")\n",
    "start_time = time.time()\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 0.15,\n",
    "    #'is_unbalance': 'true', # replaced with scale_pos_weight argument\n",
    "    'num_leaves': 7,  # 2^max_depth - 1\n",
    "    'max_depth': 3,  # -1 means no limit\n",
    "    'min_child_samples': 100,  # Minimum number of data need in a child(min_data_in_leaf)\n",
    "    'max_bin': 100,  # Number of bucketed bin for feature values\n",
    "    'subsample': 0.7,  # Subsample ratio of the training instance.\n",
    "    'subsample_freq': 1,  # frequence of subsample, <=0 means no enable\n",
    "    'colsample_bytree': 0.9,  # Subsample ratio of columns when constructing each tree.\n",
    "    'min_child_weight': 0,  # Minimum sum of instance weight(hessian) needed in a child(leaf)\n",
    "    'scale_pos_weight':99 # because training data is extremely unbalanced \n",
    "}\n",
    "bst = lgb_modelfit_nocv(params, \n",
    "                        train_df, \n",
    "                        val_df, \n",
    "                        predictors, \n",
    "                        target, \n",
    "                        objective='binary', \n",
    "                        metrics='auc',\n",
    "                        early_stopping_rounds=30, \n",
    "                        verbose_eval=True, \n",
    "                        num_boost_round=500, \n",
    "                        categorical_features=categorical)\n",
    "\n",
    "print('[{}]: model training time'.format(time.time() - start_time))\n",
    "del train_df\n",
    "del val_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(bst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"Predicting...\")\n",
    "sub['is_attributed'] = bst.predict(test_df[predictors])\n",
    "print(\"writing...\")\n",
    "sub.to_csv('sub_lgb_balanced99.csv',index=False)\n",
    "print(\"done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

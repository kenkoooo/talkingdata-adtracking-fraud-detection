{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version has improvements based on new feature engg techniques observed from different kernels. Below are few of them:\n",
    "- https://www.kaggle.com/graf10a/lightgbm-lb-0-9675\n",
    "- https://www.kaggle.com/rteja1113/lightgbm-with-count-features?scriptVersionId=2815638\n",
    "- https://www.kaggle.com/nuhsikander/lgbm-new-features-corrected?scriptVersionId=2852561\n",
    "- https://www.kaggle.com/aloisiodn/lgbm-starter-early-stopping-0-9539 (Original script)\n",
    "---\n",
    "**ここからコピー・改変**  \n",
    "https://www.kaggle.com/pranav84/lightgbm-fixing-unbalanced-data-lb-0-9680/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../data/'\n",
    "key = 'analysis_data'\n",
    "# key = 'sample'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_modelfit_nocv(params,\n",
    "                      dtrain,\n",
    "                      dvalid,\n",
    "                      predictors,\n",
    "                      target='target',\n",
    "                      objective='binary',\n",
    "                      metrics='auc',\n",
    "                      feval=None,\n",
    "                      early_stopping_rounds=20,\n",
    "                      num_boost_round=3000,\n",
    "                      verbose_eval=10,\n",
    "                      categorical_features=None):\n",
    "    lgb_params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': objective,\n",
    "        'metric':metrics,\n",
    "        'learning_rate': 0.01,\n",
    "        #'is_unbalance': 'true',  #because training data is unbalance (replaced with scale_pos_weight)\n",
    "        'num_leaves': 31,  # we should let it be smaller than 2^(max_depth)\n",
    "        'max_depth': -1,  # -1 means no limit\n",
    "        'min_child_samples': 20,  # Minimum number of data need in a child(min_data_in_leaf)\n",
    "        'max_bin': 255,  # Number of bucketed bin for feature values\n",
    "        'subsample': 0.6,  # Subsample ratio of the training instance.\n",
    "        'subsample_freq': 0,  # frequence of subsample, <=0 means no enable\n",
    "        'colsample_bytree': 0.3,  # Subsample ratio of columns when constructing each tree.\n",
    "        'min_child_weight': 5,  # Minimum sum of instance weight(hessian) needed in a child(leaf)\n",
    "        'subsample_for_bin': 200000,  # Number of samples for constructing bin\n",
    "        'min_split_gain': 0,  # lambda_l1, lambda_l2 and min_gain_to_split to regularization\n",
    "        'reg_alpha': 0,  # L1 regularization term on weights\n",
    "        'reg_lambda': 0,  # L2 regularization term on weights\n",
    "        'nthread': 4,\n",
    "        'verbose': 0,\n",
    "        'metric':metrics\n",
    "    }\n",
    "\n",
    "    lgb_params.update(params)\n",
    "\n",
    "    print(\"preparing validation datasets\")\n",
    "\n",
    "    xgtrain = lgb.Dataset(dtrain[predictors].values, label=dtrain[target].values,\n",
    "                          feature_name=predictors,\n",
    "                          categorical_feature=categorical_features\n",
    "                          )\n",
    "    xgvalid = lgb.Dataset(dvalid[predictors].values, label=dvalid[target].values,\n",
    "                          feature_name=predictors,\n",
    "                          categorical_feature=categorical_features\n",
    "                          )\n",
    "\n",
    "    evals_results = {}\n",
    "\n",
    "    bst1 = lgb.train(lgb_params, \n",
    "                     xgtrain, \n",
    "                     valid_sets=[xgtrain, xgvalid], \n",
    "                     valid_names=['train','valid'], \n",
    "                     evals_result=evals_results, \n",
    "                     num_boost_round=num_boost_round,\n",
    "                     early_stopping_rounds=early_stopping_rounds,\n",
    "                     verbose_eval=10, \n",
    "                     feval=feval)\n",
    "\n",
    "    n_estimators = bst1.best_iteration\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"n_estimators : \", n_estimators)\n",
    "    print(metrics+\":\", evals_results['valid'][metrics][n_estimators-1])\n",
    "\n",
    "    return bst1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000000, 24)\n",
      "CPU times: user 37.6 s, sys: 4.54 s, total: 42.1 s\n",
      "Wall time: 55.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path = '../../data/'\n",
    "# merge = pd.read_hdf(path + key + '.hdf', key=key)\n",
    "merge = pd.read_csv(path + key + '.csv', nrows=10000000)\n",
    "merge = merge[merge.click_date >= '2017-11-07 00:00:00']\n",
    "merge['doy'] = pd.to_datetime(merge.click_date).dt.dayofyear\n",
    "merge.drop(['ip',\n",
    "            'row_number',\n",
    "            'click_time_ch',\n",
    "            'click_time_hour',\n",
    "            'click_time_30min',\n",
    "            'click_time_15min',\n",
    "            'click_time_10min',\n",
    "            'click_time_5min',\n",
    "            'click_time_1min'], axis=1, inplace=True)\n",
    "print(merge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>click_id</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>is_test</th>\n",
       "      <th>uq_user</th>\n",
       "      <th>app_pre</th>\n",
       "      <th>...</th>\n",
       "      <th>chan_post</th>\n",
       "      <th>click_date</th>\n",
       "      <th>click_hour</th>\n",
       "      <th>cnt_1hour</th>\n",
       "      <th>cnt_30min</th>\n",
       "      <th>cnt_15min</th>\n",
       "      <th>cnt_10min</th>\n",
       "      <th>cnt_5min</th>\n",
       "      <th>cnt_1min</th>\n",
       "      <th>doy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132915856</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2211180130001</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>259.0</td>\n",
       "      <td>2017-11-08 00:00:00</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>133697186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2211180130001</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>205.0</td>\n",
       "      <td>2017-11-08 00:00:00</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133731269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2211180130001</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>280.0</td>\n",
       "      <td>2017-11-08 00:00:00</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>133731124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2211180130001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>145.0</td>\n",
       "      <td>2017-11-08 00:00:00</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134805886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2211180130001</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>145.0</td>\n",
       "      <td>2017-11-08 00:00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  click_id  app  device  os  channel  is_attributed  is_test  \\\n",
       "0  132915856       NaN   18       1  13      107              0        0   \n",
       "1  133697186       NaN   12       1  13      259              0        0   \n",
       "2  133731269       NaN    3       1  13      205              0        0   \n",
       "3  133731124       NaN    3       1  13      280              0        0   \n",
       "4  134805886       NaN   21       1  13      232              0        0   \n",
       "\n",
       "         uq_user  app_pre ...   chan_post           click_date  click_hour  \\\n",
       "0  2211180130001      9.0 ...       259.0  2017-11-08 00:00:00          21   \n",
       "1  2211180130001     18.0 ...       205.0  2017-11-08 00:00:00          21   \n",
       "2  2211180130001     12.0 ...       280.0  2017-11-08 00:00:00          21   \n",
       "3  2211180130001      3.0 ...       145.0  2017-11-08 00:00:00          21   \n",
       "4  2211180130001      8.0 ...       145.0  2017-11-08 00:00:00          22   \n",
       "\n",
       "   cnt_1hour  cnt_30min cnt_15min  cnt_10min  cnt_5min  cnt_1min  doy  \n",
       "0         20          2         1          1         1         1  312  \n",
       "1         20          3         3          3         1         1  312  \n",
       "2         20          3         3          3         2         2  312  \n",
       "3         20          3         3          3         2         2  312  \n",
       "4         11          7         6          6         6         6  312  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 24) (4676483, 24) (5323517, 24)\n"
     ]
    }
   ],
   "source": [
    "test_df = merge[merge.is_test == 1]\n",
    "train_df = merge[(merge.is_test == 0) & (merge.click_date != '2017-11-09 00:00:00')]\n",
    "val_df = merge[(merge.is_test == 0) & (merge.click_date == '2017-11-09 00:00:00')]\n",
    "print(test_df.shape, train_df.shape, val_df.shape)\n",
    "del merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "534"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'is_attributed'\n",
    "predictors = ['device', 'os', 'doy', \n",
    "              'app','app_pre', 'app_post', \n",
    "              'channel','chan_pre', 'chan_post', \n",
    "              'click_hour', 'cnt_1hour', 'cnt_15min', 'cnt_1min']\n",
    "categorical = ['device', 'os', 'doy', \n",
    "               'app','app_pre', 'app_post', \n",
    "               'channel', 'chan_pre', 'chan_post']\n",
    "sub = pd.DataFrame()\n",
    "sub['click_id'] = test_df['click_id'].astype('int')\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "preparing validation datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:681: UserWarning: categorical_feature in param dict is overrided.\n",
      "  warnings.warn('categorical_feature in param dict is overrided.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds.\n",
      "[10]\ttrain's auc: 0.978591\tvalid's auc: 0.973054\n",
      "[20]\ttrain's auc: 0.982903\tvalid's auc: 0.977601\n",
      "[30]\ttrain's auc: 0.985278\tvalid's auc: 0.980065\n",
      "[40]\ttrain's auc: 0.986591\tvalid's auc: 0.98154\n",
      "[50]\ttrain's auc: 0.987443\tvalid's auc: 0.98232\n",
      "[60]\ttrain's auc: 0.988126\tvalid's auc: 0.982853\n",
      "[70]\ttrain's auc: 0.988643\tvalid's auc: 0.983088\n",
      "[80]\ttrain's auc: 0.989006\tvalid's auc: 0.983281\n",
      "[90]\ttrain's auc: 0.989409\tvalid's auc: 0.983466\n",
      "[100]\ttrain's auc: 0.989732\tvalid's auc: 0.983589\n",
      "[110]\ttrain's auc: 0.99001\tvalid's auc: 0.983669\n",
      "[120]\ttrain's auc: 0.990301\tvalid's auc: 0.983804\n",
      "[130]\ttrain's auc: 0.990564\tvalid's auc: 0.983757\n",
      "[140]\ttrain's auc: 0.990764\tvalid's auc: 0.983785\n",
      "[150]\ttrain's auc: 0.990985\tvalid's auc: 0.983831\n",
      "[160]\ttrain's auc: 0.991179\tvalid's auc: 0.98381\n",
      "[170]\ttrain's auc: 0.991375\tvalid's auc: 0.983726\n",
      "[180]\ttrain's auc: 0.991523\tvalid's auc: 0.983727\n",
      "Early stopping, best iteration is:\n",
      "[152]\ttrain's auc: 0.991035\tvalid's auc: 0.983833\n",
      "\n",
      "Model Report\n",
      "n_estimators :  152\n",
      "auc: 0.9838333696941536\n",
      "[162.05563521385193]: model training time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training...\")\n",
    "start_time = time.time()\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 0.15,\n",
    "    #'is_unbalance': 'true', # replaced with scale_pos_weight argument\n",
    "    'num_leaves': 7,  # 2^max_depth - 1\n",
    "    'max_depth': 3,  # -1 means no limit\n",
    "    'min_child_samples': 100,  # Minimum number of data need in a child(min_data_in_leaf)\n",
    "    'max_bin': 100,  # Number of bucketed bin for feature values\n",
    "    'subsample': 0.7,  # Subsample ratio of the training instance.\n",
    "    'subsample_freq': 1,  # frequence of subsample, <=0 means no enable\n",
    "    'colsample_bytree': 0.9,  # Subsample ratio of columns when constructing each tree.\n",
    "    'min_child_weight': 0,  # Minimum sum of instance weight(hessian) needed in a child(leaf)\n",
    "    'scale_pos_weight':99 # because training data is extremely unbalanced \n",
    "}\n",
    "bst = lgb_modelfit_nocv(params, \n",
    "                        train_df, \n",
    "                        val_df, \n",
    "                        predictors, \n",
    "                        target, \n",
    "                        objective='binary', \n",
    "                        metrics='auc',\n",
    "                        early_stopping_rounds=30, \n",
    "                        verbose_eval=True, \n",
    "                        num_boost_round=500, \n",
    "                        categorical_features=categorical)\n",
    "\n",
    "print('[{}]: model training time'.format(time.time() - start_time))\n",
    "del train_df\n",
    "del val_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "writing...\n",
      "done...\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicting...\")\n",
    "sub['is_attributed'] = bst.predict(test_df[predictors])\n",
    "print(\"writing...\")\n",
    "sub.to_csv('sub_lgb_balanced99.csv',index=False)\n",
    "print(\"done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
